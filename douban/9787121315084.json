{"rating":{"max":10,"numRaters":32,"average":"7.0","min":0},"subtitle":"","author":["[美] Paul E.Mckenney（保罗·E·麦肯尼)"],"pubdate":"2017-7-1","tags":[{"count":109,"name":"并行编程","title":"并行编程"},{"count":55,"name":"计算机","title":"计算机"},{"count":52,"name":"并发","title":"并发"},{"count":50,"name":"编程","title":"编程"},{"count":36,"name":"计算机科学","title":"计算机科学"},{"count":29,"name":"软件开发","title":"软件开发"},{"count":19,"name":"Programming","title":"Programming"},{"count":16,"name":"编程艺术","title":"编程艺术"}],"origin_title":"Is Parallel Programming Hard, And, If So, What Can You Do About It?","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29484427.jpg","binding":"平装","translator":["谢宝友 鲁阳"],"catalog":"第1章  如何使用本书\t1\n1.1  路线图\t1\n1.2  小问题\t2\n1.3　除本书之外的选择\t3\n1.4  示例源代码\t4\n1.5  这本书属于谁\t4\n第2章  简介\t6\n2.1  导致并行编程困难的历史原因\t6\n2.2  并行编程的目标\t7\n2.2.1  性能\t8\n2.2.2  生产率\t9\n2.2.3  通用性\t9\n2.3  并行编程的替代方案\t11\n2.3.1  串行应用的多个实例\t11\n2.3.2  使用现有的并行软件\t11\n2.3.3  性能优化\t12\n2.4  是什么使并行编程变得复杂\t12\n2.4.1  分割任务\t13\n2.4.2  并行访问控制\t13\n2.4.3  资源分割和复制\t14\n2.4.4  与硬件的交互\t14\n2.4.5  组合使用\t14\n2.4.6  语言和环境如何支持这些任务\t14\n2.5  本章的讨论\t15\n第3章  硬件和它的习惯\t16\n3.1  概述\t16\n3.1.1  流水线CPU\t16\n3.1.2  内存引用\t17\n3.1.3  原子操作\t18\n3.1.4  内存屏障\t19\n3.1.5  高速缓存未命中\t19\n3.1.6  I\/O操作\t19\n3.2  开销\t20\n3.2.1  硬件体系结构\t20\n3.2.2  操作的开销\t21\n3.3  硬件的免费午餐\t23\n3.3.1  3D集成\t23\n3.3.2  新材料和新工艺\t24\n3.3.3  是光，不是电子\t24\n3.3.4  专用加速器\t24\n3.3.5  现有的并行软件\t25\n3.4  对软件设计的启示\t25\n第4章  办事的家伙\t27\n4.1  脚本语言\t27\n4.2  POSIX多进程\t28\n4.2.1  POSIX进程创建和销毁\t28\n4.2.2  POSIX线程创建和销毁\t30\n4.2.3  POSIX锁\t31\n4.2.4  POSIX读\/写锁\t34\n4.3  原子操作\t37\n4.4  Linux内核中类似POSIX的操作\t38\n4.5  如何选择趁手的工具\t39\n第5章  计数\t40\n5.1  为什么并发计数不可小看\t41\n5.2  统计计数器\t42\n5.2.1  设计\t43\n5.2.2  基于数组的实现\t43\n5.2.3  最终结果一致的实现\t44\n5.2.4  基于每线程变量的实现\t46\n5.2.5  本节讨论\t48\n5.3  近似上限计数器\t48\n5.3.1  设计\t48\n5.3.2  简单的上限计数实现\t50\n5.3.3  关于简单上限计数的讨论\t55\n5.3.4  近似上限计数器的实现\t55\n5.3.5  关于近似上限计数器的讨论\t55\n5.4  精确上限计数\t56\n5.4.1  原子上限计数的实现\t56\n5.4.2  关于原子上限计数的讨论\t62\n5.4.3  Signal-Theft上限计数的设计\t62\n5.4.4  Signal-Theft上限计数的实现\t63\n5.4.5  关于Signal-Theft上限计数的讨论\t68\n5.5  特殊场合的并行计数\t68\n5.6  关于并行计数的讨论\t69\n5.6.1  并行计数的性能\t70\n5.6.2  并行计数的专门化\t71\n5.6.3  从并行计数中学到什么\t71\n第6章  对分割和同步的设计\t73\n6.1  分割练习\t73\n6.1.1  哲学家就餐问题\t73\n6.1.2  双端队列\t75\n6.1.3  关于分割问题示例的讨论\t81\n6.2  设计准则\t82\n6.3  同步粒度\t83\n6.3.1  串行程序\t84\n6.3.2  代码锁\t85\n6.3.3  数据锁\t86\n6.3.4  数据所有权\t88\n6.3.5  锁粒度与性能\t88\n6.4  并行快速路径\t90\n6.4.1  读\/写锁\t91\n6.4.2  层次锁\t91\n6.4.3  资源分配器缓存\t92\n6.5  分割之外\t97\n6.5.1  使用工作队列的迷宫问题并行解法\t97\n6.5.2  另一种迷宫问题的并行解法\t100\n6.5.3  性能比较I\t102\n6.5.4  另一种迷宫问题的串行解法\t104\n6.5.5  性能比较II\t104\n6.5.6  未来展望与本节总结\t105\n6.6  分割、并行化与优化\t106\n第7章  锁\t107\n7.1  努力活着\t108\n7.1.1  死锁\t108\n7.1.2  活锁与饥饿\t114\n7.1.3  不公平的锁\t116\n7.1.4  低效率的锁\t117\n7.2  锁的类型\t117\n7.2.1  互斥锁\t117\n7.2.2  读\/写锁\t118\n7.2.3  读\/写锁之外\t118\n7.2.4  范围锁\t119\n7.3  锁在实现中的问题\t121\n7.3.1  基于原子交换的互斥锁实现示例\t121\n7.3.2  互斥锁的其他实现\t122\n7.4  基于锁的存在保证\t124\n7.5  锁：是英雄还是恶棍\t125\n7.5.1  应用程序中的锁：英雄\t125\n7.5.2  并行库中的锁：只是一个工具\t126\n7.5.3  并行化串行库时的锁：恶棍\t128\n7.6  总结\t130\n第8章  数据所有权\t131\n8.1  多进程\t131\n8.2  部分数据所有权和pthread线程库\t132\n8.3  函数输送\t132\n8.4  指派线程\t132\n8.5  私有化\t133\n8.6  数据所有权的其他用途\t133\n第9章  延后处理\t134\n9.1  引用计数\t134\n9.1.1  各种引用计数的实现\t135\n9.1.2  危险指针\t140\n9.1.3  支持引用计数的Linux原语\t141\n9.1.4  计数优化\t142\n9.2  顺序锁\t142\n9.3  读-复制-修改（RCU）\t145\n9.3.1  RCU介绍\t145\n9.3.2  RCU基础\t147\n9.3.3  RCU用法\t155\n9.3.4  Linux内核中的RCU API\t166\n9.3.5  “玩具式”的RCU实现\t171\n9.3.6  RCU练习\t188\n9.4  如何选择？\t188\n9.5  更新端怎么办\t190\n第10章  数据结构\t191\n10.1  从例子入手\t191\n10.2  可分割的数据结构\t192\n10.2.1  哈希表的设计\t192\n10.2.2  哈希表的实现\t192\n10.2.3  哈希表的性能\t195\n10.3  读侧重的数据结构\t197\n10.3.1  受RCU保护的哈希表的实现\t197\n10.3.2  受RCU保护的哈希表的性能\t199\n10.3.3  对受RCU保护的哈希表的讨论\t201\n10.4  不可分割的数据结构\t201\n10.4.1  可扩展哈希表的设计\t202\n10.4.2  可扩展哈希表的实现\t203\n10.4.3  可扩展哈希表的讨论\t210\n10.4.4  其他可扩展的哈希表\t211\n10.5  其他数据结构\t214\n10.6  微优化\t214\n10.6.1  实例化\t215\n10.6.2  比特与字节\t215\n10.6.3  硬件层面的考虑\t216\n10.7  总结\t217\n第11章  验证\t218\n11.1  简介\t218\n11.1.1  BUG来自于何处\t218\n11.1.2  所需的心态\t220\n11.1.3  应该何时开始验证\t221\n11.1.4  开源之路\t221\n11.2  跟踪\t222\n11.3  断言\t223\n11.4  静态分析\t224\n11.5  代码走查\t224\n11.5.1  审查\t224\n11.5.2  走查\t225\n11.5.3  自查\t225\n11.6  几率及海森堡BUG\t227\n11.6.1  离散测试统计\t228\n11.6.2  滥用离散测试统计\t229\n11.6.3  持续测试统计\t229\n11.6.4  定位海森堡BUG\t232\n11.7  性能评估\t235\n11.7.1  性能基准\t236\n11.7.2  剖析\t236\n11.7.3  差分分析\t237\n11.7.4  微基准\t237\n11.7.5  隔离\t237\n11.7.6  检测干扰\t238\n11.8  总结\t242\n第12章  形式验证\t244\n12.1  通用目的的状态空间搜索\t244\n12.1.1  Promela和Spin\t244\n12.1.2  如何使用 Promela\t249\n12.1.3  Promela 示例: 锁\t251\n12.1.4  Promela 示例: QRCU\t254\n12.1.5  Promela初试牛刀：dynticks和可抢占RCU\t260\n12.1.6  验证可抢占RCU和dynticks\t264\n12.2  特定目的的状态空间搜索\t288\n12.2.1  解析Litmus测试\t289\n12.2.2  Litmus测试意味着什么\t290\n12.2.3  运行Litmus测试\t291\n12.2.4  PPCMEM讨论\t292\n12.3  公理方法\t293\n12.4  SAT求解器\t294\n12.5  总结\t295\n第13章  综合应用\t296\n13.1  计数难题\t296\n13.1.1  对更新进行计数\t296\n13.1.2  对查找进行计数\t296\n13.2  使用RCU拯救并行软件性能\t297\n13.2.1  RCU和基于每CPU变量的统计计数\t297\n13.2.2  RCU及可插拔I\/O设备的计数器\t300\n13.2.3  数组及长度\t300\n13.2.4  相关联的字段\t301\n13.3  散列难题\t302\n13.3.1  相关联的数据元素\t302\n13.3.2  更新友好的哈希表遍历\t303\n第14章  高级同步\t304\n14.1  避免锁\t304\n14.2  内存屏障\t304\n14.2.1  内存序及内存屏障\t305\n14.2.2  如果B在A后面，并且C在B后面，为什么C不在A后面\t306\n14.2.3  变量可以拥有多个值\t307\n14.2.4  能信任什么东西\t308\n14.2.5  锁实现回顾\t312\n14.2.6  一些简单的规则\t313\n14.2.7  抽象内存访问模型\t314\n14.2.8  设备操作\t315\n14.2.9  保证\t315\n14.2.10  什么是内存屏障\t316\n14.2.11  锁约束\t325\n14.2.12  内存屏障示例\t326\n14.2.13  CPU缓存的影响\t328\n14.2.14  哪里需要内存屏障\t329\n14.3  非阻塞同步\t329\n14.3.1  简单NBS\t330\n14.3.2  NBS讨论\t331\n第15章  并行实时计算\t332\n15.1  什么是实时计算\t332\n15.1.1  软实时\t332\n15.1.2  硬实时\t333\n15.1.3  现实世界的实时\t334\n15.2  谁需要实时计算\t336\n15.3  谁需要并行实时计算\t337\n15.4  实现并行实时系统\t337\n15.4.1  实现并行实时操作系统\t339\n15.4.2  实现并行实时应用\t349\n15.5  实时VS.快速：如何选择\t351\n第16章  易于使用\t353\n16.1  简单是什么\t353\n16.2  API设计的Rusty准则\t353\n16.3  修整Mandelbrot集合\t354\n第17章  未来的冲突\t357\n17.1  曾经的CPU技术不代表未来\t357\n17.1.1  单处理器Uber Alles\t358\n17.1.2  多线程Mania\t359\n17.1.3  更多类似的场景\t359\n17.1.4  撞上内存墙\t359\n17.2  事务内存\t360\n17.2.1  外部世界\t361\n17.2.2  进程修改\t364\n17.2.3  同步\t367\n17.2.4  讨论\t370\n17.3  硬件事务内存\t371\n17.3.1  HTM与锁相比的优势\t372\n17.3.2  HTM与锁相比的劣势\t373\n17.3.3  HTM与增强后的锁机制相比的劣势\t379\n17.3.4  HTM最适合的场合\t380\n17.3.5  潜在的搅局者\t380\n17.3.6  结论\t382\n17.4  并行函数式编程\t383\n附录A  重要问题\t385\nA.1 “After”的含义是什么\t385\nA.2 “并发”和“并行”之间的差异是什么\t388\nA.3  现在是什么时间\t389\n附录B  同步原语\t391\nB.1  组织和初始化\t391\nB.1.1  smp_init()\t391\nB.2  线程创建、销毁及控制\t392\nB.2.1  create_thread()\t392\nB.2.2  smp_thread_id()\t392\nB.2.3  for_each_thread()\t392\nB.2.4  for_each_running_thread()\t392\nB.2.5  wait_thread()\t393\nB.2.6  wait_all_threads()\t393\nB.2.7  用法示例\t393\nB.3  锁\t394\nB.3.1  spin_lock_init()\t394\nB.3.2  spin_lock()\t394\nB.3.3  spin_trylock()\t394\nB.3.4  spin_unlock()\t394\nB.3.5  用法示例\t395\nB.4  每线程变量\t395\nB.4.1  DEFINE_PER_THREAD()\t395\nB.4.2  DECLARE_PER_THREAD()\t395\nB.4.3  per_thread()\t395\nB.4.4  __get_thread_var()\t396\nB.4.5  init_per_thread()\t396\nB.4.6  用法示例\t396\nB.5  性能\t396\n附录C  为什么需要内存屏障\t397\nC.1  缓存结构\t397\nC.2  缓存一致性协议\t399\nC.2.1  MESI状态\t399\nC.2.2  MESI协议消息\t400\nC.2.3  MESI状态图\t400\nC.2.4  MESI协议示例\t401\nC.3  存储导致不必要的停顿\t402\nC.3.1  存储缓冲\t403\nC.3.2  存储转发\t403\nC.3.3  存储缓冲区及内存屏障\t404\nC.4  存储序列导致不必要的停顿\t406\nC.4.1  使无效队列\t406\nC.4.2  使无效队列及使无效应答\t407\nC.4.3  使无效队列及内存屏障\t407\nC.5  读和写内存屏障\t409\nC.6  内存屏障示例\t410\nC.6.1  乱序体系结构\t410\nC.6.2  示例1\t411\nC.6.3  示例2\t412\nC.6.4  示例3\t412\nC.7  特定的内存屏障指令\t413\nC.7.1  Alpha\t414\nC.7.2  AMD64\t417\nC.7.3  ARMv7-A\/R\t417\nC.7.4  IA64\t418\nC.7.5  PA-RISC\t418\nC.7.6  POWER \/ Power PC\t418\nC.7.7  SPARC RMO、PSO及TSO\t419\nC.7.8  x86\t420\nC.7.9  zSeries\t421\nC.8  内存屏障是永恒的吗\t421\nC.9  对硬件设计者的建议\t422\n附录D  问题答案\t423\nD.1  如何使用本书\t423\nD.2  简介\t424\nD.3  硬件和它的习惯\t427\nD.4  办事的家伙\t429\nD.5  计数\t433\nD.6  对分割和同步的设计\t445\nD.7  锁\t449\nD.8  数据所有权\t455\nD.9  延迟处理\t456\nD.10  数据结构\t471\nD.11  验证\t473\nD.12  形式验证\t478\nD.13  综合应用\t481\nD.14  高级同步\t483\nD.15  并行实时计算\t486\nD.16  易于使用\t487\nD.17  未来的冲突\t487\nD.18  重要问题\t490\nD.19  同步原语\t491\nD.20  为什么需要内存屏障\t491\n附录E  术语\t495\n附录F  感谢\t502\nF.1  评审者\t502\nF.2  硬件提供者\t502\nF.3  原始出处\t503\nF.4  图表作者\t503\nF.5  其他帮助\t505","pages":"514","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29484427.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29484427.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29484427.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27078711\/","id":"27078711","publisher":"电子工业出版社","isbn10":"7121315084","isbn13":"9787121315084","title":"深入理解并行编程","url":"https:\/\/api.douban.com\/v2\/book\/27078711","alt_title":"Is Parallel Programming Hard, And, If So, What Can You Do About It?","author_intro":"Paul E. McKenney is the core contributor of Linux kernel .","summary":"《深入理解并行编程》首先以霍金提出的两个理论物理限制为引子，解释了多核并行计算兴起的原因，并从硬件的角度阐述并行编程的难题。接着，《深入理解并行编程》以常见的计数器为例，探讨其不同的实现方法及适用场景。在这些实现方法中，除了介绍常见的锁以外，《深入理解并行编程》还重点介绍了RCU的使用及其原理，以及实现RCU的基础：内存屏障。最后，《深入理解并行编程》还介绍了并行软件的验证，以及并行实时计算等内容。\n《深入理解并行编程》适合于对并行编程有兴趣的大学生、研究生，以及需要对项目进行深度性能优化的软硬件工程师，特别值得一提的是，《深入理解并行编程》对操作系统内核工程师也很有价值。","price":"129"}