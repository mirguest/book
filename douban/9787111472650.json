{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"GPU编程权威指南","author":["[美] Nicholas Wilt"],"pubdate":"2014-8-26","tags":[{"count":16,"name":"CUDA","title":"CUDA"},{"count":8,"name":"GPU","title":"GPU"},{"count":5,"name":"parallel","title":"parallel"},{"count":3,"name":"计算机","title":"计算机"},{"count":3,"name":"CUDA&GPGPU","title":"CUDA&GPGPU"},{"count":2,"name":"苏统华","title":"苏统华"},{"count":2,"name":"已购买","title":"已购买"},{"count":2,"name":"programming","title":"programming"}],"origin_title":"The CUDA Handbook: A Comprehensive Guide to GPU Programming","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27453604.jpg","binding":"平装","translator":["苏统华"],"catalog":"《CUDA专家手册：GPU编程权威指南》\n中文版序\n推荐序\n译者序\n前言\n第一部分基础知识\n第1章简介2\n1.1方法4\n1.2代码4\n1.2.1验证型代码5\n1.2.2演示型代码5\n1.2.3探究型代码5\n1.3资源5\n1.3.1开源代码5\n1.3.2cuda专家手册库（chlib）6\n1.3.3编码风格6\n1.3.4cuda sdk6\n1.4结构6\n第2章硬件架构8\n2.1cpu配置8\n2.1.1前端总线9\n2.1.2对称处理器簇9\n2.1.3非一致内存访问（numa）10\n2.1.4集成的pcie12\n2.2集成gpu13\n2.3多gpu14\n2.4cuda中的地址空间17\n2.4.1虚拟寻址简史17\n2.4.2不相交的地址空间20\n2.4.3映射锁页内存21\n2.4.4可分享锁页内存21\n2.4.5统一寻址23\n2.4.6点对点映射24\n2.5cpu\/gpu交互24\n2.5.1锁页主机内存和命令缓冲区25\n2.5.2cpu\/gpu并发26\n2.5.3主机接口和内部gpu同步29\n2.5.4gpu间同步31\n2.6gpu架构31\n2.6.1综述31\n2.6.2流处理器簇34\n2.7延伸阅读37\n第3章软件架构39\n3.1软件层39\n3.1.1cuda运行时和驱动程序40\n3.1.2驱动程序模型41\n3.1.3nvcc、ptx和微码43\n3.2设备与初始化45\n3.2.1设备数量46\n3.2.2设备属性46\n3.2.3无cuda支持情况48\n3.3上下文50\n3.3.1生命周期与作用域51\n3.3.2资源预分配51\n3.3.3地址空间52\n3.3.4当前上下文栈52\n3.3.5上下文状态53\n3.4模块与函数53\n3.5内核（函数）55\n3.6设备内存56\n3.7流与事件57\n3.7.1软件流水线57\n3.7.2流回调57\n3.7.3null流57\n3.7.4事件58\n3.8主机内存59\n3.8.1锁页主机内存60\n3.8.2可分享的锁页内存60\n3.8.3映射锁页内存60\n3.8.4主机内存注册60\n3.9cuda数组与纹理操作61\n3.9.1纹理引用61\n3.9.2表面引用63\n3.10图形互操作性63\n3.11cuda运行时与cuda驱动程序api65\n第4章软件环境69\n4.1nvcc——cuda编译器驱动程序69\n4.2ptxas——ptx汇编工具73\n4.3cuobjdump76\n4.4nvidia-smi77\n4.5亚马逊web服务79\n4.5.1命令行工具79\n4.5.2ec2和虚拟化79\n4.5.3密钥对80\n4.5.4可用区域（az）和地理区域81\n4.5.5s381\n4.5.6ebs81\n4.5.7ami82\n4.5.8ec2上的linux82\n4.5.9ec2上的windows83\n第二部分cuda编程\n第5章内存88\n5.1主机内存89\n5.1.1分配锁页内存89\n5.1.2可共享锁页内存90\n5.1.3映射锁页内存90\n5.1.4写结合锁页内存91\n5.1.5注册锁页内存91\n5.1.6锁页内存与统一虚拟寻址92\n5.1.7映射锁页内存用法92\n5.1.8numa、线程亲和性与锁页内存93\n5.2全局内存95\n5.2.1指针96\n5.2.2动态内存分配97\n5.2.3查询全局内存数量100\n5.2.4静态内存分配101\n5.2.5内存初始化api102\n5.2.6指针查询103\n5.2.7点对点内存访问104\n5.2.8读写全局内存105\n5.2.9合并限制105\n5.2.10验证实验：内存峰值带宽107\n5.2.11原子操作111\n5.2.12全局内存的纹理操作113\n5.2.13ecc（纠错码）113\n5.3常量内存114\n5.3.1主机与设备常量内存114\n5.3.2访问常量内存114\n5.4本地内存115\n5.5纹理内存118\n5.6共享内存118\n5.6.1不定大小共享内存声明119\n5.6.2束同步编码119\n5.6.3共享内存的指针119\n5.7内存复制119\n5.7.1同步内存复制与异步内存复制120\n5.7.2统一虚拟寻址121\n5.7.3cuda运行时121\n5.7.4驱动程序api123\n第6章流与事件125\n6.1cpu\/gpu的并发：隐藏驱动程序开销126\n6.2异步的内存复制129\n6.2.1异步的内存复制：主机端到设备端130\n6.2.2异步内存复制：设备端到主机端130\n6.2.3null流和并发中断131\n6.3cuda事件：cpu\/gpu同步133\n6.3.1阻塞事件135\n6.3.2查询135\n6.4cuda事件：计时135\n6.5并发复制和内核处理136\n6.5.1concurrencymemcpykernel.cu137\n6.5.2性能结果141\n6.5.3中断引擎间的并发性142\n6.6映射锁页内存143\n6.7并发内核处理145\n6.8gpu\/gpu同步：cudastreamwaitevent()146\n6.9源代码参考147\n第7章内核执行148\n7.1概况148\n7.2语法149\n7.2.1局限性150\n7.2.2高速缓存和一致性151\n7.2.3异步与错误处理151\n7.2.4超时152\n7.2.5本地内存152\n7.2.6共享内存153\n7.3线程块、线程、线程束、束内线程153\n7.3.1线程块网格153\n7.3.2执行保证156\n7.3.3线程块与线程id156\n7.4占用率159\n7.5动态并行160\n7.5.1作用域和同步161\n7.5.2内存模型162\n7.5.3流与事件163\n7.5.4错误处理163\n7.5.5编译和链接164\n7.5.6资源管理164\n7.5.7小结165\n第8章流处理器簇167\n8.1内存168\n8.1.1寄存器168\n8.1.2本地内存169\n8.1.3全局内存170\n8.1.4常量内存171\n8.1.5共享内存171\n8.1.6栅栏和一致性173\n8.2整型支持174\n8.2.1乘法174\n8.2.2其他操作（位操作）175\n8.2.3漏斗移位（sm 3.5）175\n8.3浮点支持176\n8.3.1格式176\n8.3.2单精度（32位）180\n8.3.3双精度（64位）181\n8.3.4半精度（16位）181\n8.3.5案例分析：float到half的转换182\n8.3.6数学函数库185\n8.3.7延伸阅读190\n8.4条件代码191\n8.4.1断定191\n8.4.2分支与汇聚191\n8.4.3特殊情况：最小值、最大值和绝对值192\n8.5纹理与表面操作193\n8.6其他指令193\n8.6.1线程束级原语193\n8.6.2线程块级原语194\n8.6.3性能计数器195\n8.6.4视频指令195\n8.6.5特殊寄存器196\n8.7指令集196\n第9章多gpu203\n9.1概述203\n9.2点对点机制204\n9.2.1点对点内存复制204\n9.2.2点对点寻址205\n9.3uva：从地址推断设备206\n9.4多gpu间同步207\n9.5单线程多gpu方案208\n9.5.1当前上下文栈208\n9.5.2n-体问题210\n9.6多线程多gpu方案212\n第10章纹理操作216\n10.1简介216\n10.2纹理内存217\n10.2.1设备内存217\n10.2.2cuda数组与块的线性寻址218\n10.2.3设备内存与cuda数组对比222\n10.3一维纹理操作223\n10.4纹理作为数据读取方式226\n10.4.1增加有效地址范围226\n10.4.2主机内存纹理操作228\n10.5使用非归一化坐标的纹理操作230\n10.6使用归一化坐标的纹理操作237\n10.7一维表面内存的读写238\n10.8二维纹理操作240\n10.9二维纹理操作：避免复制242\n10.9.1设备内存上的二维纹理操作242\n10.9.2二维表面内存的读写243\n10.10三维纹理操作244\n10.11分层纹理245\n10.11.1一维分层纹理246\n10.11.2二维分层纹理246\n10.12最优线程块大小选择以及性能246\n10.13纹理操作快速参考248\n10.13.1硬件能力248\n10.13.2cuda运行时249\n10.13.3驱动api250\n第三部分实例\n第11章流式负载254\n11.1设备内存255\n11.2异步内存复制258\n11.3流259\n11.4映射锁页内存260\n11.5性能评价与本章小结261\n第12章归约算法263\n12.1概述263\n12.2两遍归约265\n12.3单遍归约269\n12.4使用原子操作的归约271\n12.5任意线程块大小的归约272\n12.6适应任意数据类型的归约273\n12.7基于断定的归约276\n12.8基于洗牌指令的线程束归约277\n第13章扫描算法278\n13.1定义与变形278\n13.2概述279\n13.3扫描和电路设计281\n13.4cuda实现284\n13.4.1先扫描再扇出284\n13.4.2先归约再扫描（递归）288\n13.4.3先归约再扫描（两阶段）291\n13.5线程束扫描294\n13.5.1零填充295\n13.5.2带模板的版本296\n13.5.3线程束洗牌297\n13.5.4指令数对比298\n13.6流压缩300\n13.7参考文献（并行扫描算法）302\n13.8延伸阅读（并行前缀求和电路）303\n第14章n-体问题304\n14.1概述305\n14.2简单实现309\n14.3基于共享内存实现312\n14.4基于常量内存实现313\n14.5基于线程束洗牌实现315\n14.6多gpu及其扩展性316\n14.7cpu的优化317\n14.8小结321\n14.9参考文献与延伸阅读323\n第15章图像处理的归一化相关系数计算324\n15.1概述324\n15.2简单的纹理实现326\n15.3常量内存中的模板329\n15.4共享内存中的图像331\n15.5进一步优化334\n15.5.1基于流处理器簇的实现代码334\n15.5.2循环展开335\n15.6源代码336\n15.7性能评价337\n15.8延伸阅读339\n附录acuda专家手册库340\n术语表347","pages":"350","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27453604.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27453604.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27453604.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25976234\/","id":"25976234","publisher":"机械工业出版社","isbn10":"7111472659","isbn13":"9787111472650","title":"CUDA专家手册","url":"https:\/\/api.douban.com\/v2\/book\/25976234","alt_title":"The CUDA Handbook: A Comprehensive Guide to GPU Programming","author_intro":"Nicholas Wilt拥有逾25年底层编程经验，他的技术兴趣跨越多个领域，包括工业机器视觉、图形处理和底层多媒体软件开发等。作为英伟达公司CUDA首席架构师，他见证了CUDA从无到有的整个过程，设计并实现了多数CUDA的底层抽象机制。在加入英伟达公司之前，他曾在微软公司担任Direct3D 5．0和6．0产品的开发组组长，完成了Windows桌面管理器的原型开发，并在此期间开展了早期GPU计算的工作。目前，Wilt先生任职于亚马逊公司，从事与GPU产品相关的云计算技术。\n苏统华，博士，英伟达中国首批CUDA官方认证工程师，英伟达官方认证CUDA培训师，哈尔滨工业大学英伟达教学中心负责人，主要研究领域包括大规模并行计算、模式识别、物联网智能信息处理、智能媒体交互与计算等。2013年，其所开发的CUDA识别算法，在文档分析和识别国际会议(ICDAR’2013)上获得手写汉字识别竞赛的双料冠军。另外，他在手写汉字识别领域建立了里程碑式工作，论文他引约300次；他所建立的HIT-MW库，为全世界100多家科研院所采用；目前负责国家自然科学基金项目2项。著有英文专著《Chinese Handwriting Recognition：An Algorithmic Perspective》(德国施普林格出版社)，CUDA*II关译作2本(机械工业出版社)。现任哈尔滨工业大学软件学院高级讲师、硕士生导师。","summary":"《CUDA专家手册：GPU编程权威指南》由英伟达公司CUDA首席架构师Nicholas Wilt亲笔撰写，深度解析GPU的架构、系统软件、编程环境，以及CUDA编程各方面的知识和各种优化技术，包含大量实用代码示例，是并行程序开发领域最有影响力的著作之一。\n《CUDA专家手册：GPU编程权威指南》分为三部分，共15章。第一部分(第1～4章)介绍CUDA开发的基础知识、硬件／软件架构和软件环境；第二部分(第5～10章)详细解析CUDA开发的各个方面，包括内存、流与事件、内核执行、流处理器簇、多gpu编程和纹理操作；第三部分(第11～15章)利用多个实例，深入分析流式负载、归约算法、扫描算法、N-体问题和图像处理的归一化相关系数计算，介绍如何应用各种优化技术。","series":{"id":"42081","title":"高性能计算技术丛书"},"price":"85.00元"}