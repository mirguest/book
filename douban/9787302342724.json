{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["David B. Kirk","Wen-mei W. Hwu"],"pubdate":"2013-11","tags":[{"count":12,"name":"CUDA","title":"CUDA"},{"count":9,"name":"并行计算","title":"并行计算"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"gpu","title":"gpu"},{"count":2,"name":"C++","title":"C++"},{"count":1,"name":"程序设计","title":"程序设计"},{"count":1,"name":"科学","title":"科学"},{"count":1,"name":"并行编程","title":"并行编程"}],"origin_title":"Programming Massively Parallel Processors","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27195561.jpg","binding":"","translator":["赵开勇","汪朝辉","程亦超"],"catalog":"第1章 引言 1\n1.1 异构并行计算 2\n1.2 现代GPU的体系结构 6\n1.3 为什么需要更高的速度和并行化 8\n1.4 应用程序的加速 9\n1.5 并行编程语言和模型 11\n1.6 本书的总体目标 12\n1.7 本书的组织结构 13\n参考文献 16\n第2章 GPU计算的发展历程 19\n2.1 图形流水线的发展 19\n2.1.1 固定功能的图形流水线时代 20\n2.1.2 可编程实时图形流水线的发展 23\n2.1.3 图形与计算结合的处理器 25\n2.2 GPGPU：一个中间步骤 27\n2.3 GPU计算 28\n2.3.1 可扩展的GPU 29\n2.3.2 发展近况 29\n2.3.3 未来发展趋势 30\n参考文献与课外阅读 30\n第3章 CUDA简介 35\n3.1 数据并行性 36\n3.2 CUDA的程序结构 37\n3.3 向量加法kernel函数 39\n3.4 设备全局存储器与数据传输 41\n3.5 kernel函数与线程 46\n3.6 小结 50\n3.6.1 函数声明 50\n3.6.2 启动kernel函数 50\n3.6.3 预定义变量 51\n3.6.4 运行时API 51\n3.7 习题 51\n参考文献 53\n第4章 数据并行执行模型 55\n4.1 CUDA的线程组织 56\n4.2 线程与多维数据的映射 59\n4.3 矩阵乘法——一个更加复杂的kernel函数 65\n4.4 线程同步和透明的可扩展性 70\n4.5 线程块的资源分配 73\n4.6 查询设备属性 74\n4.7 线程调度和容许时延 75\n4.8 小结 78\n4.9 习题 79\n第5章 CUDA存储器 81\n5.1 存储器访问效率的重要性 82\n5.2 CUDA设备存储器的类型 83\n5.3 减少全局存储器流量的一种策略 89\n5.4 分块矩阵乘法的kernel函数 93\n5.5 存储器——限制并行性的一个因素 98\n5.6 小结 100\n5.7 习题 101\n第6章 性能优化 103\n6.1 WARP和线程执行 104\n6.2 全局存储器的带宽 111\n6.3 执行资源的动态划分 118\n6.4 指令混合和线程粒度 120\n6.5 小结 121\n6.6 习题 121\n参考文献 124\n第7章 浮点运算 127\n7.1 浮点格式 128\n7.1.1 M的规范化表示 128\n7.1.2 E的余码表示 129\n7.2 能表示的数 130\n7.3 特殊的位模式与IEEE格式中的精度 134\n7.4 算术运算的准确度和舍入 135\n7.5 算法的优化 136\n7.6 数值稳定性 137\n7.7 小结 141\n7.8 习题 141\n参考文献 142\n第8章 并行模式：卷积 143\n8.1 背景 144\n8.2 一个基本算法：一维并行卷积 148\n8.3 常数存储器和高速缓存 149\n8.4 使用光环元素的分块一维卷积 153\n8.5 一个更简单的分块一维卷积——通用高速缓存 158\n8.6 小结 160\n8.7 习题 161\n第9章 并行模式：前缀和 163\n9.1 背景 164\n9.2 简单并行扫描 165\n9.3 考虑工作效率 169\n9.4 工作高效的并行扫描 170\n9.5 任意输入长度的并行扫描 174\n9.6 小结 177\n9.7 习题 177\n参考文献 178\n第10章 并行模式：稀疏矩阵-向量乘法 179\n10.1 背景 180\n10.2 使用CSR格式的并行SpMV 183\n10.3 填充与转置 184\n10.4 用混合方法来控制填充 186\n10.5 通过排序和划分来规则化 189\n10.6 小结 191\n10.7 习题 191\n参考文献 192\n第11章 应用案例研究：高级MRI重构 193\n11.1 应用背景 194\n11.2 迭代重构 197\n11.3 计算FHD 198\n11.4 最终评估 214\n11.5 习题 217\n参考文献 218\n第12章 应用案例研究：分子可视化和分析 219\n12.1 应用背景 220\n12.2 kernel函数简单的实现方案 221\n12.3 线程粒度调节 225\n12.4 存储器合并 227\n12.5 小结 230\n12.6 习题 231\n参考文献 232\n第13章 并行编程和计算思想 233\n13.1 并行计算的目标 234\n13.2 问题分解 235\n13.3 算法选择 238\n13.4 计算思想 243\n13.5 小结 244\n13.6 习题 244\n参考文献 244\n第14章 OpenCL简介 245\n14.1 背景 246\n14.2 数据并行性模型 247\n14.3 设备的体系结构 249\n14.4 kernel函数 250\n14.5 设备管理和启动kernel 251\n14.6 OpenCL中的静电势图谱 254\n14.7 小结 258\n14.8 习题 258\n参考文献 259\n第15章 OpenACC并行编程 261\n15.1 OpenACC与CUDA C的比较 261\n15.2 执行模型 263\n15.3 存储器模型 265\n15.4 基本的OpenACC程序 266\n15.4.1 并行构造 266\n15.4.2 循环构造 267\n15.4.3 kernels构造 272\n15.4.4 数据管理 275\n15.4.5 数据构造 276\n15.4.6 异步计算和数据传输 278\n15.5 OpenACC的发展方向 279\n15.6 习题 280\n第16章 Thrust：一个面向效率的CUDA编程库 281\n16.1 背景简介 282\n16.2 动机 284\n16.3 Thrust的基本特性 284\n16.3.1 迭代器和内存空间 286\n16.3.2 互操作性 286\n16.4 泛型编程 288\n16.5 抽象的益处 290\n16.5.1 编程效率 290\n16.5.2 鲁棒性 291\n16.5.3 真实性能 291\n16.6 最佳范例 293\n16.6.1 融合 293\n16.6.2 数组结构体 294\n16.6.3 隐式范围 296\n16.7 习题 297\n参考文献 298\n第17章 CUDA FORTRAN 299\n17.1 CUDA FORTRAN和CUDA C的区别 300\n17.2 第一个CUDA FORTRAN程序 301\n17.3 CUDA FORTRAN中的多维数组 303\n17.4 用通用接口重载主机\/设备端例程 304\n17.5 通过iso_c_binding调用CUDA C 307\n17.6 kernel循环指令和归约操作 309\n17.7 动态共享存储器 310\n17.8 异步数据传输 311\n17.9 编译和性能剖析 316\n17.10 在CUDA FORTRAN中调用Thrust 317\n17.11 习题 321\n第18章 C++ AMP简介 323\n18.1 C++ AMP核心特性 324\n18.2 C++ AMP执行模式详解 329\n18.2.1 显式和隐式的数据复制 330\n18.2.2 异步操作 331\n18.2.3 本节小结 333\n18.3 加速器管理 333\n18.4 分块执行 335\n18.5 C++ AMP图形特性 338\n18.6 小结 340\n18.7 习题 341\n第19章 异构集群编程 343\n19.1 背景简介 344\n19.2 运行示例 344\n19.3 MPI基础 346\n19.4 MPI点对点通信模型 348\n19.5 重叠计算和通信 355\n19.6 MPI集合通信模型 362\n19.7 小结 363\n19.8 习题 363\n参考文献 364\n第20章 CUDA动态并行 365\n20.1 背景 366\n20.2 动态并行简介 367\n20.3 重要细节 368\n20.3.1 启动环境变量设置 369\n20.3.2 API错误和启动失败 369\n20.3.3 事件 369\n20.3.4 流 369\n20.3.5 同步范围 370\n20.4 内存可见性 371\n20.4.1 全局内存 371\n20.4.2 零拷贝内存 371\n20.4.3 常量内存 371\n20.4.4 局部内存 371\n20.4.5 共享内存 372\n20.4.6 纹理内存 372\n20.5 一个简单示例 373\n20.6 运行时限制 376\n20.6.1 内存占用 376\n20.6.2 嵌套深度 376\n20.6.3 内存分配和生存周期 376\n20.6.4 ECC错误 377\n20.6.5 流 377\n20.6.6 事件 377\n20.6.7 启动池 377\n20.7 一个更复杂的示例 378\n20.7.1 线性贝塞尔曲线 378\n20.7.2 二次贝塞尔曲线 378\n20.7.3 贝塞尔曲线计算(非动态并行版本) 378\n20.7.4 贝塞尔曲线计算(使用动态并行) 381\n20.8 小结 384\n参考文献 384\n第21章 结论与展望 385\n21.1 重点回顾 385\n21.2 存储器模型的演变 386\n21.2.1 大型虚拟和物理地址空间 386\n21.2.2 统一的设备存储空间 388\n21.2.3 可配置的缓存和暂时存储器 388\n21.2.4 提高原子操作的速度 389\n21.2.5 提高全局内存的访问速度 389\n21.3 kernel函数执行控制过程的演变 389\n21.3.1 kernel函数内部的函数调用 389\n21.3.2 kernel函数中的异常处理 390\n21.3.3 多个kernel函数的同步执行 390\n21.3.4 可中断的kernel函数 391\n21.4 内核的性能 391\n21.4.1 双精度的速度 391\n21.4.2 更好的控制流效率 392\n21.5 编程环境 392\n21.6 美好前景 392\n参考文献 393\n附录A 矩阵乘法主机版的源代码 395\n附录B GPU的计算能力 407","pages":"432","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27195561.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27195561.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27195561.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25805801\/","id":"25805801","publisher":"清华大学出版社","isbn10":"7302342725","isbn13":"9787302342724","title":"大规模并行处理器编程实战（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/25805801","alt_title":"Programming Massively Parallel Processors","author_intro":"David B. Kirk院士：美国国家工程院院士，NVIDIA院士、前首席科学家，也是CUDA技术的创始人之一，2002年曾荣获ACM SIGGRAPH计算机图形成就奖。他拥有麻省理工学院的机械工程学学士和硕士学位，加州理工学院的计算机科学博士学位。Kirk是50项与图形芯片设计相关的专利和专利申请的发明者，发表了50多篇关于图形处理技术的论文，是可视化计算技术方面的权威。\nWen-mei W. Hwu(胡文美)教授：拥有美国加州大学伯克利分校计算机科学博士学位，担任美国伊利诺伊大学厄巴纳-香槟分校(UIUC)协调科学实验室电气与计算机工程AMD创始人Jerry Sanders讲席教授(Walter J. SandersⅢAdvanced Micro Devices Endowed Chair)。胡文美教授还是IEEE(国际电气电子工程师学会)院士，ACM(美国计算机学会)院士。","summary":"","price":"59.80"}