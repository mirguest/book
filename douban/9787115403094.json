{"rating":{"max":10,"numRaters":355,"average":"7.9","min":0},"subtitle":"","author":["[美] Holden Karau","[美] Andy Konwinski","[美] Patrick Wendell","[加] Matei Zaharia"],"pubdate":"2015-10","tags":[{"count":322,"name":"大数据","title":"大数据"},{"count":240,"name":"spark","title":"spark"},{"count":164,"name":"数据分析","title":"数据分析"},{"count":139,"name":"Spark","title":"Spark"},{"count":77,"name":"计算机","title":"计算机"},{"count":57,"name":"bigdata","title":"bigdata"},{"count":49,"name":"数据平台","title":"数据平台"},{"count":32,"name":"技术","title":"技术"}],"origin_title":"Learning Spark: Lightning-Fast Big Data Analysis","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28300707.jpg","binding":"","translator":["王道远"],"catalog":"目录\n推荐序  xi\n译者序  xiv\n序  xvi\n前言  xvii\n第1章 Spark数据分析导论  1\n1.1 Spark是什么  1\n1.2 一个大一统的软件栈  2\n1.2.1 Spark Core  2\n1.2.2 Spark SQL  3\n1.2.3 Spark Streaming  3\n1.2.4 MLlib  3\n1.2.5 GraphX  3\n1.2.6 集群管理器  4\n1.3 Spark的用户和用途  4\n1.3.1 数据科学任务  4\n1.3.2 数据处理应用  5\n1.4 Spark简史  5\n1.5 Spark的版本和发布  6\n1.6 Spark的存储层次  6\n第2章 Spark下载与入门  7\n2.1 下载Spark  7\n2.2 Spark中Python和Scala的shell  9\n2.3 Spark 核心概念简介  12\n2.4 独立应用  14\n2.4.1 初始化SparkContext  15\n2.4.2 构建独立应用  16\n2.5 总结  19\n第3章 RDD编程  21\n3.1 RDD基础  21\n3.2 创建RDD  23\n3.3 RDD操作  24\n3.3.1 转化操作  24\n3.3.2 行动操作  26\n3.3.3 惰性求值  27\n3.4 向Spark传递函数  27\n3.4.1 Python  27\n3.4.2 Scala  28\n3.4.3 Java  29\n3.5 常见的转化操作和行动操作  30\n3.5.1 基本RDD  30\n3.5.2 在不同RDD类型间转换  37\n3.6 持久化( 缓存)  39\n3.7 总结  40\n第4章 键值对操作  41\n4.1 动机  41\n4.2 创建Pair RDD  42\n4.3 Pair RDD的转化操作  42\n4.3.1 聚合操作  45\n4.3.2 数据分组  49\n4.3.3 连接  50\n4.3.4 数据排序  51\n4.4 Pair RDD的行动操作  52\n4.5 数据分区（进阶）  52\n4.5.1 获取RDD的分区方式  55\n4.5.2 从分区中获益的操作  56\n4.5.3 影响分区方式的操作  57\n4.5.4 示例：PageRank  57\n4.5.5 自定义分区方式  59\n4.6 总结  61\n第5章 数据读取与保存  63\n5.1 动机  63\n5.2 文件格式  64\n5.2.1 文本文件  64\n5.2.2 JSON  66\n5.2.3 逗号分隔值与制表符分隔值  68\n5.2.4 SequenceFile  71\n5.2.5 对象文件  73\n5.2.6 Hadoop输入输出格式  73\n5.2.7 文件压缩  77\n5.3 文件系统  78\n5.3.1 本地\/“常规”文件系统  78\n5.3.2 Amazon S3  78\n5.3.3 HDFS  79\n5.4 Spark SQL中的结构化数据  79\n5.4.1 Apache Hive  80\n5.4.2 JSON  80\n5.5 数据库  81\n5.5.1 Java数据库连接  81\n5.5.2 Cassandra  82\n5.5.3 HBase  84\n5.5.4 Elasticsearch  85\n5.6 总结  86\n第6章 Spark编程进阶  87\n6.1 简介  87\n6.2 累加器  88\n6.2.1 累加器与容错性  90\n6.2.2 自定义累加器  91\n6.3 广播变量  91\n6.4 基于分区进行操作  94\n6.5 与外部程序间的管道  96\n6.6 数值RDD 的操作  99\n6.7 总结  100\n第7章 在集群上运行Spark  101\n7.1 简介  101\n7.2 Spark运行时架构  101\n7.2.1 驱动器节点  102\n7.2.2 执行器节点  103\n7.2.3 集群管理器  103\n7.2.4 启动一个程序  104\n7.2.5 小结  104\n7.3 使用spark-submit 部署应用  105\n7.4 打包代码与依赖  107\n7.4.1 使用Maven构建的用Java编写的Spark应用  108\n7.4.2 使用sbt构建的用Scala编写的Spark应用  109\n7.4.3 依赖冲突   111\n7.5 Spark应用内与应用间调度  111\n7.6 集群管理器  112\n7.6.1 独立集群管理器  112\n7.6.2 Hadoop YARN  115\n7.6.3 Apache Mesos  116\n7.6.4 Amazon EC2  117\n7.7 选择合适的集群管理器  120\n7.8 总结  121\n第8章 Spark调优与调试  123\n8.1 使用SparkConf配置Spark  123\n8.2 Spark执行的组成部分：作业、任务和步骤  127\n8.3 查找信息  131\n8.3.1 Spark网页用户界面  131\n8.3.2 驱动器进程和执行器进程的日志  134\n8.4 关键性能考量  135\n8.4.1 并行度  135\n8.4.2 序列化格式  136\n8.4.3 内存管理  137\n8.4.4 硬件供给  138\n8.5 总结  139\n第9章 Spark SQL  141\n9.1 连接Spark SQL  142\n9.2 在应用中使用Spark SQL  144\n9.2.1 初始化Spark SQL  144\n9.2.2 基本查询示例  145\n9.2.3 SchemaRDD  146\n9.2.4 缓存  148\n9.3 读取和存储数据  149\n9.3.1 Apache Hive  149\n9.3.2 Parquet  150\n9.3.3 JSON  150\n9.3.4 基于RDD  152\n9.4 JDBC\/ODBC服务器  153\n9.4.1 使用Beeline  155\n9.4.2 长生命周期的表与查询  156\n9.5 用户自定义函数  156\n9.5.1 Spark SQL UDF  156\n9.5.2 Hive UDF  157\n9.6 Spark SQL性能  158\n9.7 总结  159\n第10章 Spark Streaming  161\n10.1 一个简单的例子  162\n10.2 架构与抽象  164\n10.3 转化操作  167\n10.3.1 无状态转化操作  167\n10.3.2 有状态转化操作  169\n10.4 输出操作  173\n10.5 输入源  175\n10.5.1 核心数据源  175\n10.5.2 附加数据源  176\n10.5.3 多数据源与集群规模  179\n10.6 24\/7不间断运行  180\n10.6.1 检查点机制  180\n10.6.2 驱动器程序容错  181\n10.6.3 工作节点容错  182\n10.6.4 接收器容错  182\n10.6.5 处理保证  183\n10.7 Streaming用户界面  183\n10.8 性能考量  184\n10.8.1 批次和窗口大小  184\n10.8.2 并行度  184\n10.8.3 垃圾回收和内存使用  185\n10.9 总结  185\n第11章 基于MLlib的机器学习  187\n11.1 概述  187\n11.2 系统要求  188\n11.3 机器学习基础  189\n11.4 数据类型  192\n11.5 算法  194\n11.5.1 特征提取  194\n11.5.2 统计  196\n11.5.3 分类与回归  197\n11.5.4 聚类  202\n11.5.5 协同过滤与推荐  203\n11.5.6 降维  204\n11.5.7 模型评估  206\n11.6 一些提示与性能考量  206\n11.6.1 准备特征  206\n11.6.2 配置算法  207\n11.6.3 缓存RDD以重复使用  207\n11.6.4 识别稀疏程度  207\n11.6.5 并行度  207\n11.7 流水线API  208\n11.8 总结  209\n作者简介  210\n封面介绍  210","pages":"232","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28300707.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28300707.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28300707.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26616244\/","id":"26616244","publisher":"人民邮电出版社","isbn10":"7115403090","isbn13":"9787115403094","title":"Spark快速大数据分析","url":"https:\/\/api.douban.com\/v2\/book\/26616244","alt_title":"Learning Spark: Lightning-Fast Big Data Analysis","author_intro":"Holden Karau是Databricks的软件开发工程师，活跃于开源社区。她还著有《Spark快速数据处理》。\nAndy Konwinski是Databricks联合创始人，Apache Spark项目技术专家，还是Apache Mesos项目的联合发起人。\nPatrick Wendell是Databricks联合创始人，也是Apache Spark项目技术专家。他还负责维护Spark核心引擎的几个子系统。\nMatei Zaharia是Databricks的CTO，同时也是Apache Spark项目发起人以及Apache基金会副主席。","summary":"","series":{"id":"660","title":"图灵程序设计丛书"},"price":"59.00元"}